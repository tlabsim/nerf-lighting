{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd00dffb5442d84be890217d664a91c46e420962c190ec91d07047007dfcc46efe8",
   "display_name": "Python 3.7.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0dffb5442d84be890217d664a91c46e420962c190ec91d07047007dfcc46efe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NeRF Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "d:\\NeRF\\nerf-lighting\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "__basedir__ = os.path.dirname(os.path.realpath('.'))\n",
    "print(__basedir__)\n",
    "if __basedir__ not in sys.path:\n",
    "     sys.path.insert(0, __basedir__)\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from run_nerf_helpers import *\n",
    "from nerf_renderer import *\n",
    "from misc_helpers import *\n",
    "from load_llff import load_llff_data\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIRARCHICAL_SAMPLING_METHOD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    datadir = os.path.normcase(os.path.join(__basedir__, args.datadir))\n",
    "    images, poses, bds, render_poses, i_test = load_llff_data(datadir, args.factor,\n",
    "                                                                  recenter=True, bd_factor=.75,\n",
    "                                                                  spherify=args.spherify)\n",
    "    hwf = poses[0, :3, -1]\n",
    "    H, W, focal = hwf\n",
    "    H, W = int(H), int(W)\n",
    "\n",
    "    poses = poses[:, :3, :4]\n",
    "    print('Loaded llff', images.shape,\n",
    "            render_poses.shape, hwf, args.datadir)\n",
    "\n",
    "    print('DEFINING BOUNDS')\n",
    "    if args.no_ndc:\n",
    "        near = tf.reduce_min(bds) * .9\n",
    "        far = tf.reduce_max(bds) * 1.\n",
    "    else:\n",
    "        near = 0.\n",
    "        far = 1.\n",
    "    print('NEAR FAR', near, far)   \n",
    "\n",
    "    return images, poses, H, W, focal, near, far, bds, render_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MODEL_NERF 63 27 <class 'int'> <class 'int'> True\n(None, 90) (None, 63) (None, 27)\nMODEL_NERF 63 27 <class 'int'> <class 'int'> True\n(None, 90) (None, 63) (None, 27)\n{'network_query_fn': <function network_query_fn at 0x00000263363FAAF8>, 'perturb': 1.0, 'N_importance': 128, 'network_fine': <tensorflow.python.keras.engine.functional.Functional object at 0x000002634DBCEFC8>, 'N_samples': 64, 'network_fn': <tensorflow.python.keras.engine.functional.Functional object at 0x000002634DB9F708>, 'use_viewdirs': True, 'white_bkgd': False, 'raw_noise_std': 1.0, 'chunk': 32768, 'ndc': False, 'lindisp': False}\n"
     ]
    }
   ],
   "source": [
    "if HEIRARCHICAL_SAMPLING_METHOD == 1:\n",
    "    args_file = '../data/rubiks/cropped/logs/rubiks/args.txt'\n",
    "else:\n",
    "    args_file = '../data/rubiks2/logs/rubiks2/args.txt'\n",
    "args = ConfigReader(args_file)\n",
    "\n",
    "embed_fn, input_ch = get_embedder(args.multires, args.i_embed)\n",
    "\n",
    "input_ch_views = 0\n",
    "embeddirs_fn = None\n",
    "if args.use_viewdirs:\n",
    "    embeddirs_fn, input_ch_views = get_embedder(\n",
    "        args.multires_views, args.i_embed)\n",
    "output_ch = 4\n",
    "skips = [4]\n",
    "model = init_nerf_model(\n",
    "    D=args.netdepth, W=args.netwidth,\n",
    "    input_ch=input_ch, output_ch=output_ch, skips=skips,\n",
    "    input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs)\n",
    "\n",
    "model_fine = None\n",
    "model_fine = init_nerf_model(\n",
    "    D=args.netdepth_fine, W=args.netwidth_fine,\n",
    "    input_ch=input_ch, output_ch=output_ch, skips=skips,\n",
    "    input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs)\n",
    "\n",
    "def network_query_fn(inputs, viewdirs, network_fn): return run_network(\n",
    "    inputs, viewdirs, network_fn,\n",
    "    embed_fn=embed_fn,\n",
    "    embeddirs_fn=embeddirs_fn,\n",
    "    netchunk=args.netchunk)\n",
    "\n",
    "render_kwargs = {\n",
    "    'network_query_fn': network_query_fn,\n",
    "    'perturb': args.perturb,\n",
    "    'N_importance': args.N_importance,\n",
    "    'network_fine': model_fine,\n",
    "    'N_samples': args.N_samples,\n",
    "    'network_fn': model,\n",
    "    'use_viewdirs': args.use_viewdirs,\n",
    "    'white_bkgd': args.white_bkgd,\n",
    "    'raw_noise_std': args.raw_noise_std,\n",
    "    'chunk': args.chunk,\n",
    "    'ndc': False,\n",
    "    'lindisp': args.lindisp\n",
    "}\n",
    "\n",
    "print(render_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HEIRARCHICAL_SAMPLING_METHOD == 1:\n",
    "    model_coarse_weights_file = '../data/rubiks/cropped/logs/rubiks/model_500000.npy'\n",
    "    model_fine_weights_file = '../data/rubiks/cropped/logs/rubiks/model_fine_500000.npy'\n",
    "\n",
    "    model.set_weights(np.load(model_coarse_weights_file, allow_pickle=True))\n",
    "    model_fine.set_weights(np.load(model_fine_weights_file, allow_pickle=True))\n",
    "else:\n",
    "    model_coarse_weights_file = '../data/rubiks2/logs/rubiks2/model_350000.npy'\n",
    "    model_fine_weights_file = '../data/rubiks2/logs/rubiks2/model_fine_350000.npy'\n",
    "\n",
    "    model.set_weights(np.load(model_coarse_weights_file, allow_pickle=True))\n",
    "    model_fine.set_weights(np.load(model_fine_weights_file, allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded image data (500, 500, 3, 132) [ 500.         500.        1098.8775858]\n",
      "Loaded d:\\nerf\\nerf-lighting\\.\\data\\rubiks2\\ 2.2962166918186226 11.288918670814095\n",
      "Data:\n",
      "(132, 3, 5) (132, 500, 500, 3) (132, 2)\n",
      "HOLDOUT view is 128\n",
      "Loaded llff (132, 500, 500, 3) (120, 3, 5) [ 500.      500.     1098.8776] ./data/rubiks2/\n",
      "DEFINING BOUNDS\n",
      "NEAR FAR tf.Tensor(0.46544135, shape=(), dtype=float32) tf.Tensor(2.5425055, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "images, poses, H, W, focal, near, far, bds, render_poses = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16 8\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 43\n",
    "\n",
    "results = []\n",
    "\n",
    "for ns in [16]:\n",
    "    for ni in [8]:\n",
    "        print(ns, ni)\n",
    "        render_kwargs['N_samples'] = ns\n",
    "        render_kwargs['N_importance'] = ni\n",
    "\n",
    "        start = time.time()\n",
    "        rgb, disp, acc, _ = render(H, W, focal, near=near, far=far, c2w=poses[i, :3, :4], retraw=False, **render_kwargs)\n",
    "        elapsed = time.time() - start\n",
    "        psnr = mse2psnr(img2mse(images[i], rgb))\n",
    "        _psnr = psnr.numpy().item()\n",
    "        results.append([ns, ni, elapsed, psnr.numpy()])\n",
    "        \n",
    "        plt.imsave(f'../outputs/ns_ni_test2/{ns}_{ni}_{round(elapsed, 3)}_{round(_psnr, 3)}.png', rgb.numpy())\n",
    "\n",
    "results = np.array(results, dtype = np.float32)\n",
    "with open(f'../outputs/ns_ni_test2/results.npy', 'wb') as f:\n",
    "    np.save(f, results)\n",
    "\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(2.22222, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results[:5, 1], results[:5, 3], label = 'n_samples = 64')\n",
    "plt.plot(results[5:10, 1], results[5:10, 3], label = 'n_samples = 32')\n",
    "plt.plot(results[10:15, 1], results[10:15, 3], label = 'n_samples = 16')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = results[:, 0], results[:, 1], results[:, 2]\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z,\n",
    "           linewidths=1, alpha=.7,\n",
    "           edgecolor='k',\n",
    "           s = 200,\n",
    "           c=z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ = acc.numpy()[..., np.newaxis]\n",
    "acc_.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([images[i], rgb, acc_], 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(f'../outputs/acc_test/{i}_original.png', images[i])\n",
    "plt.imsave(f'../outputs/acc_test/{i}_rgb.png', rgb.numpy())\n",
    "plt.imsave(f'../outputs/acc_test/{i}_acc.png', acc.numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psnr(images, poses, near, far):\n",
    "    rgbs = []\n",
    "    psnrs = []    \n",
    "    for i, target in enumerate(images):\n",
    "        print('Rendering ', i + 1)\n",
    "        rgb, _, _, _ = render(H, W, focal, near=near, far=far, c2w=poses[i, :3, :4], retraw=False, **render_kwargs)\n",
    "        rgbs.append(rgb)\n",
    "        psnr = mse2psnr(img2mse(rgb, target))\n",
    "        psnrs.append(psnr)\n",
    "        del rgb\n",
    "\n",
    "    return rgbs, psnrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = images[::8]\n",
    "test_poses = poses[::8]\n",
    "test_images.shape, test_poses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbs, psnrs = get_psnr(images, poses, near, far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(rgbs, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('../outputs/res_sampling_test_img82.png', images[82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_psnr = lambda x: tf.reduce_mean(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(rgbs, 14, 10, scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(rgbs[128:], 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_psnr(psnrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_psnr(psnrs[::8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_test = np.arange(images.shape[0])[::8]\n",
    "i_train = np.array([i for i in np.arange(int(images.shape[0])) if  i not in i_test])\n",
    "train_psnrs = [psnrs[i] for i in i_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_psnr(psnrs[::8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}